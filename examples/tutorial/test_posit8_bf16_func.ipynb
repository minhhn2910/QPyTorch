{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62f72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/himeshi/.cache/torch_extensions/py310_cu126 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/himeshi/.cache/torch_extensions/py310_cu126/quant_cpu/build.ninja...\n",
      "Building extension module quant_cpu...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module quant_cpu...\n",
      "Using /home/himeshi/.cache/torch_extensions/py310_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/himeshi/.cache/torch_extensions/py310_cu126/quant_cuda/build.ninja...\n",
      "/home/himeshi/conga25/conga25env/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module quant_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module quant_cuda...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import qtorch\n",
    "from qtorch.quant import bfloat16_posit8_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f0e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-20.0000, -17.5000, -15.0000, -12.5000, -10.0000,  -7.5000,  -5.0000,\n",
      "         -2.5000,   0.0000,   2.5000,   5.0000,   7.5000,  10.0000,  12.5000,\n",
      "         15.0000,  17.5000])\n",
      "tensor([-20.0000, -17.5000, -15.0000, -12.5000, -10.0000,  -7.5000,  -5.0000,\n",
      "         -2.5000,   0.0000,   2.5000,   5.0000,   7.5000,  10.0000,  12.5000,\n",
      "         15.0000,  17.5000], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(-20,20,2.5)\n",
    "a = torch.tensor(a, dtype=torch.float)\n",
    "print (a)\n",
    "\n",
    "b = a.to(torch.bfloat16)\n",
    "print (b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96fc5600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-20.0000, -16.0000, -15.0000, -12.0000, -10.0000,  -7.5000,  -5.0000,\n",
      "         -2.5000,   0.0000,   2.5000,   5.0000,   7.5000,  10.0000,  12.0000,\n",
      "         15.0000,  16.0000], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "c = bfloat16_posit8_quantize(b,nsize=8,es=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd10f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-16.0000, -16.0000, -16.0000,  -8.0000,  -6.0000,  -4.0000,  -1.5000,\n",
      "         -6.0000,   0.0000,   6.0000,   1.5000,   4.0000,   6.0000,   8.0000,\n",
      "         16.0000,  16.0000], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "d = bfloat16_posit8_quantize(b,nsize=7,es=2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e94d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-16., -16., -16.,  -4.,  -1.,  -1.,  -1.,  -1.,   0.,   1.,   1.,   1.,\n",
      "          1.,   4.,  16.,  16.], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "e = bfloat16_posit8_quantize(b,nsize=6,es=2)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090102e3",
   "metadata": {},
   "source": [
    "Test GPU functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd69c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-20.0000, -17.5000, -15.0000, -12.5000, -10.0000,  -7.5000,  -5.0000,\n",
      "         -2.5000,   0.0000,   2.5000,   5.0000,   7.5000,  10.0000,  12.5000,\n",
      "         15.0000,  17.5000], device='cuda:0')\n",
      "tensor([-20.0000, -17.5000, -15.0000, -12.5000, -10.0000,  -7.5000,  -5.0000,\n",
      "         -2.5000,   0.0000,   2.5000,   5.0000,   7.5000,  10.0000,  12.5000,\n",
      "         15.0000,  17.5000], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Get the GPU device\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Copy the tensor to the GPU device\n",
    "a_gpu = a.to(device)\n",
    "print(a_gpu)\n",
    "\n",
    "b_gpu = a_gpu.to(torch.bfloat16)\n",
    "print(b_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0884f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-20.0000, -16.0000, -15.0000, -12.0000, -10.0000,  -7.5000,  -5.0000,\n",
      "         -2.5000,   0.0000,   2.5000,   5.0000,   7.5000,  10.0000,  12.0000,\n",
      "         15.0000,  16.0000], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "c_gpu = bfloat16_posit8_quantize(b_gpu,nsize=8,es=1)\n",
    "print(c_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106ce6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-16.0000, -16.0000, -16.0000,  -8.0000,  -6.0000,  -4.0000,  -6.0000,\n",
      "         -1.5000,   0.0000,   1.5000,   6.0000,   4.0000,   6.0000,   8.0000,\n",
      "         16.0000,  16.0000], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "d_gpu = bfloat16_posit8_quantize(b_gpu,nsize=7,es=1)\n",
    "print(d_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beac3a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-16., -16., -16.,  -4.,  -1.,  -1.,  -1.,  -1.,   0.,   1.,   1.,   1.,\n",
      "          1.,   4.,  16.,  16.], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "e_gpu = bfloat16_posit8_quantize(b_gpu,nsize=6,es=2)\n",
    "print(e_gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conga25env (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
